{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dae10e3e",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n",
    "In this notebook we will explore the different datasets we are going to be using to fine-tune our Transformer model. The objective of this model is to be able to detect (classify) spanish news articles between 2 classes (binary): `Fake` and `Real`. After analysis all datasets we will build an unique dataset including all data (clean, standarized, etc...).\n",
    "\n",
    "#### Datasets to analyze\n",
    "* `Spanish Fake and Real News` - Universidad de Madrid.\n",
    "* `Spanish Political Fake News`- Universidad de Vigo.\n",
    "* `Noticias falsas en español` - Kaggle (includes both fake and true datasets).\n",
    "* `Fake News Corpus Spanish` - by jpposadas (Github).\n",
    "\n",
    "In the future we could try adding more datasets or getting data our self by scraping it from news sites or sites that already provide the labelling of fake or real. But as a first model we will go with this 4 datasets which initially have 58370 articles in total (before data clean up)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fce9371f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c593d4",
   "metadata": {},
   "source": [
    "### Spanish Fake and Real News\n",
    "\n",
    "This dataset was created for a final project in a cybersecurity master's program by a student from the Polytechnic University of Madrid. It mainly contains news from 2019.\n",
    "\n",
    "The kaggle page made available 2 csv files:\n",
    "* `spanishFakeNews.csv` - Training data.\n",
    "* `testSpanishFakeNews.csv` - Testing data.\n",
    "\n",
    "As we are going to use also a validation set, we will perform the split at the end using the final dataset.\n",
    "\n",
    "Dataset page: [Spanish Fake and Real News - Kaggle](https://www.kaggle.com/datasets/zulanac/fake-and-real-news)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bbad4709",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset shape: (538, 2)\n",
      "Training dataset count:\n",
      "text     538\n",
      "label    538\n",
      "dtype: int64\n",
      "Training dataset labels: ['fake' 'real']\n"
     ]
    }
   ],
   "source": [
    "spanish_fake_real_news_df = pd.read_csv(\"../data/preview/spanishFakeNews.csv\", names=[\"text\", \"label\"], header=0)\n",
    "\n",
    "print(f\"Training dataset shape: {spanish_fake_real_news_df.shape}\")\n",
    "print(f\"Training dataset count:\\n{spanish_fake_real_news_df.count()}\")\n",
    "print(f\"Training dataset labels: {spanish_fake_real_news_df['label'].unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd0dedf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing dataset shape: (60, 2)\n",
      "Testing dataset count:\n",
      "text     60\n",
      "label    60\n",
      "dtype: int64\n",
      "Testing dataset labels: ['fake' 'real']\n"
     ]
    }
   ],
   "source": [
    "spanish_fake_real_news_test_df = pd.read_csv(\"../data/preview/testSpanishFakeNews.csv\", names=[\"text\", \"label\"], header=0)\n",
    "\n",
    "print(f\"Testing dataset shape: {spanish_fake_real_news_test_df.shape}\")\n",
    "print(f\"Testing dataset count:\\n{spanish_fake_real_news_test_df.count()}\")\n",
    "print(f\"Testing dataset labels: {spanish_fake_real_news_test_df['label'].unique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aebd7b1",
   "metadata": {},
   "source": [
    "##### Create final `Spanish Fake and Real News` dataset\n",
    "\n",
    "After loading both datasets we are going to join them as one final dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67ccd7ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final dataset shape: (598, 2)\n",
      "Final dataset count:\n",
      "text     598\n",
      "label    598\n",
      "dtype: int64\n",
      "Final dataset labels: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Usuario\\AppData\\Local\\Temp\\ipykernel_14244\\823461895.py:2: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  spanish_fake_real_news_df[\"label\"] = spanish_fake_real_news_df[\"label\"].replace({'real': 1 , 'fake': 0}).astype(\"int8\")\n",
      "C:\\Users\\Usuario\\AppData\\Local\\Temp\\ipykernel_14244\\823461895.py:3: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  spanish_fake_real_news_test_df[\"label\"] = spanish_fake_real_news_test_df[\"label\"].replace({'real': 1 , 'fake': 0}).astype(\"int8\")\n"
     ]
    }
   ],
   "source": [
    "# Replace \"categorical\" labels with numerical labels in both training and testing datasets\n",
    "spanish_fake_real_news_df[\"label\"] = spanish_fake_real_news_df[\"label\"].replace({'real': 1 , 'fake': 0}).astype(\"int8\")\n",
    "spanish_fake_real_news_test_df[\"label\"] = spanish_fake_real_news_test_df[\"label\"].replace({'real': 1 , 'fake': 0}).astype(\"int8\")\n",
    "\n",
    "# Join together both datasets\n",
    "spanish_fake_real_news_final_df = pd.concat(objs=[spanish_fake_real_news_df, spanish_fake_real_news_test_df], ignore_index=True)\n",
    "spanish_fake_real_news_final_df = spanish_fake_real_news_final_df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "\n",
    "print(f\"Final dataset shape: {spanish_fake_real_news_final_df.shape}\")\n",
    "print(f\"Final dataset count:\\n{spanish_fake_real_news_final_df.count()}\")\n",
    "print(f\"Final dataset labels: {spanish_fake_real_news_final_df['label'].unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6a74bd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Articles length information: \n",
      "count     598.000000\n",
      "mean      387.428094\n",
      "std       325.559810\n",
      "min        11.000000\n",
      "25%       232.250000\n",
      "50%       334.500000\n",
      "75%       479.750000\n",
      "max      4669.000000\n",
      "Name: length_words, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Create a column with the number of characters\n",
    "spanish_fake_real_news_final_df[\"length_words\"] = spanish_fake_real_news_final_df[\"text\"].str.split().str.len()\n",
    "\n",
    "print(\"Articles length information: \")\n",
    "print(spanish_fake_real_news_final_df[\"length_words\"].describe())\n",
    "\n",
    "spanish_fake_real_news_final_df = spanish_fake_real_news_final_df.drop(columns=[\"length_words\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f53cf904",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "1    339\n",
       "0    259\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if the dataset is balanced (Real articles have aprox. 30% more)\n",
    "spanish_fake_real_news_final_df[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe7b50f",
   "metadata": {},
   "source": [
    "### Spanish Political Fake News\n",
    "\n",
    "This dataset was created for a thesis by a student at the University of Vigo. It contains news articles from April 2017 to June 2023. And it's main focus is in politics articles.\n",
    "\n",
    "The kaggle page made available 1 csv file:\n",
    "* `D57000_complete.csv` - Contains all data.\n",
    "\n",
    "***Observation**: Instead of including a text or something similar it includes a description and a lot of articles are Null, so we will have to analyze it properly and see what we keep*.\n",
    "\n",
    "Dataset page: [Spanish Political Fake News - Kaggle](https://www.kaggle.com/datasets/javieroterovizoso/spanish-political-fake-news)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f779a84b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset shape: (57231, 3)\n",
      "Training dataset count:\n",
      "label    57231\n",
      "title    57231\n",
      "text     57231\n",
      "dtype: int64\n",
      "Training dataset labels: [1 0]\n"
     ]
    }
   ],
   "source": [
    "spanish_political_fake_news_df = pd.read_csv(\"../data/preview/D57000_complete.csv\", sep=\";\", names=[\"id\", \"label\", \"title\", \"text\", \"date\"], header=0)\n",
    "spanish_political_fake_news_df = spanish_political_fake_news_df.drop(columns=[\"id\", \"date\"])\n",
    "\n",
    "print(f\"Training dataset shape: {spanish_political_fake_news_df.shape}\")\n",
    "print(f\"Training dataset count:\\n{spanish_political_fake_news_df.count()}\")\n",
    "print(f\"Training dataset labels: {spanish_political_fake_news_df['label'].unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "94afd997",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine title with text to make articles a bit longer\n",
    "spanish_political_fake_news_df[\"text\"] = spanish_political_fake_news_df[\"text\"] + spanish_political_fake_news_df[\"title\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5772115a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Articles length information: \n",
      "count    57231.000000\n",
      "mean        53.054603\n",
      "std         15.960961\n",
      "min          8.000000\n",
      "25%         43.000000\n",
      "50%         51.000000\n",
      "75%         61.000000\n",
      "max        199.000000\n",
      "Name: length_words, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Create a column with the number of characters\n",
    "spanish_political_fake_news_df[\"length_words\"] = spanish_political_fake_news_df[\"text\"].str.split().str.len()\n",
    "\n",
    "print(\"Articles length information: \")\n",
    "print(spanish_political_fake_news_df[\"length_words\"].describe())\n",
    "\n",
    "spanish_political_fake_news_df = spanish_political_fake_news_df.drop(columns=[\"length_words\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe01547",
   "metadata": {},
   "source": [
    "### Noticias falsas en español\n",
    "\n",
    "We don't have much information about this dataset as it was not provided by the authors. The only think we know is that it includes 2 csv files:\n",
    "\n",
    "* `onlyfakes1000.csv` - Containing almost 1k of fake news articles (965).\n",
    "* `onlytrue1000.csv` - Containing almost 1k of real news articles (993).\n",
    "\n",
    "Dataset page: [Noticias falsas en español - Kaggle](https://www.kaggle.com/datasets/arseniitretiakov/noticias-falsas-en-espaol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3c6c16be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset shape: (1000, 2)\n",
      "Training dataset count:\n",
      "text     1000\n",
      "label    1000\n",
      "dtype: int64\n",
      "Training dataset labels: [0]\n"
     ]
    }
   ],
   "source": [
    "only_fake_df = pd.read_csv(\"../data/preview/onlyfakes1000.csv\", names=[\"text\"], header=0)\n",
    "only_fake_df[\"label\"] = 0\n",
    "\n",
    "print(f\"Training dataset shape: {only_fake_df.shape}\")\n",
    "print(f\"Training dataset count:\\n{only_fake_df.count()}\")\n",
    "print(f\"Training dataset labels: {only_fake_df['label'].unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4fe9ac6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset shape: (1000, 2)\n",
      "Training dataset count:\n",
      "text     1000\n",
      "label    1000\n",
      "dtype: int64\n",
      "Training dataset labels: [1]\n"
     ]
    }
   ],
   "source": [
    "only_true_df = pd.read_csv(\"../data/preview/onlytrue1000.csv\", names=[\"text\"], header=0)\n",
    "only_true_df[\"label\"] = 1\n",
    "\n",
    "print(f\"Training dataset shape: {only_true_df.shape}\")\n",
    "print(f\"Training dataset count:\\n{only_true_df.count()}\")\n",
    "print(f\"Training dataset labels: {only_true_df['label'].unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5579ef12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final dataset shape: (2000, 2)\n",
      "Final dataset count:\n",
      "text     2000\n",
      "label    2000\n",
      "dtype: int64\n",
      "Final dataset labels: [0 1]\n"
     ]
    }
   ],
   "source": [
    "# Join together both datasets\n",
    "true_fake_final_df = pd.concat(objs=[only_fake_df, only_true_df], ignore_index=True)\n",
    "true_fake_final_df = true_fake_final_df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "\n",
    "print(f\"Final dataset shape: {true_fake_final_df.shape}\")\n",
    "print(f\"Final dataset count:\\n{true_fake_final_df.count()}\")\n",
    "print(f\"Final dataset labels: {true_fake_final_df['label'].unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c1469902",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Articles length information: \n",
      "count    2000.000000\n",
      "mean       39.680500\n",
      "std        14.310969\n",
      "min         6.000000\n",
      "25%        39.000000\n",
      "50%        42.000000\n",
      "75%        45.000000\n",
      "max       379.000000\n",
      "Name: length_words, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Create a column with the number of characters\n",
    "true_fake_final_df[\"length_words\"] = true_fake_final_df[\"text\"].str.split().str.len()\n",
    "\n",
    "print(\"Articles length information: \")\n",
    "print(true_fake_final_df[\"length_words\"].describe())\n",
    "\n",
    "true_fake_final_df = true_fake_final_df.drop(columns=[\"length_words\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7237024",
   "metadata": {},
   "source": [
    "### Fake News Corpus Spanish\n",
    "\n",
    "It contains a collection of 971 news divided into 491 real news and 480 fake news. The corpus covers news from 9 different topics: Science, Sport, Economy, Education, Entertainment, Politics, Health, Security, and Society. And the articles were published between November 2020 and March 2021.\n",
    "\n",
    "Extra information provided by the author is that the articles come from a variaty of countries: Argentina, Bolivia, Chile, Colombia, Costa Rica, Ecuador, Spain, United States, France, Peru, Uruguay, England and Venezuela.\n",
    "\n",
    "It provides 3 xlsx files:\n",
    "* `train.xlsx` - Training data.\n",
    "* `development.xlsx` - Development/Validation data.\n",
    "* `test.xlsx` - Testing data.\n",
    "\n",
    "Dataset page: [Fake News Corpus Spanish - jpposadas Github](https://github.com/jpposadas/FakeNewsCorpusSpanish)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "39717132",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset shape: (676, 2)\n",
      "Training dataset count:\n",
      "label    676\n",
      "text     676\n",
      "dtype: int64\n",
      "Training dataset labels: ['Fake' 'True']\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_excel(\"../data/preview/train.xlsx\", names=[\"id\", \"label\", \"topic\", \"source\", \"headline\", \"text\", \"link\"], header=0)\n",
    "train_df = train_df.drop(columns=[\"id\", \"topic\", \"source\", \"link\", \"headline\"])\n",
    "\n",
    "print(f\"Training dataset shape: {train_df.shape}\")\n",
    "print(f\"Training dataset count:\\n{train_df.count()}\")\n",
    "print(f\"Training dataset labels: {train_df['label'].unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f8a6ed75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Development dataset shape: (295, 2)\n",
      "Development dataset count:\n",
      "label    295\n",
      "text     295\n",
      "dtype: int64\n",
      "Development dataset labels: ['Fake' 'True']\n"
     ]
    }
   ],
   "source": [
    "development_df = pd.read_excel(\"../data/preview/development.xlsx\", names=[\"id\", \"label\", \"topic\", \"source\", \"headline\", \"text\", \"link\"], header=0)\n",
    "development_df = development_df.drop(columns=[\"id\", \"topic\", \"source\", \"link\", \"headline\"])\n",
    "\n",
    "print(f\"Development dataset shape: {development_df.shape}\")\n",
    "print(f\"Development dataset count:\\n{development_df.count()}\")\n",
    "print(f\"Development dataset labels: {development_df['label'].unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "371f6a03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test dataset shape: (572, 2)\n",
      "Test dataset count:\n",
      "label    572\n",
      "text     572\n",
      "dtype: int64\n",
      "Test dataset labels: [ True False]\n"
     ]
    }
   ],
   "source": [
    "test_df = pd.read_excel(\"../data/preview/test.xlsx\", names=[\"id\", \"label\", \"topic\", \"source\", \"headline\", \"text\", \"link\"], header=0)\n",
    "test_df = test_df.drop(columns=[\"id\", \"topic\", \"source\", \"link\", \"headline\"])\n",
    "\n",
    "print(f\"Test dataset shape: {test_df.shape}\")\n",
    "print(f\"Test dataset count:\\n{test_df.count()}\")\n",
    "print(f\"Test dataset labels: {test_df['label'].unique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b06a138",
   "metadata": {},
   "source": [
    "##### Create final `Fake News Corpus Spanish` dataset\n",
    "\n",
    "After loading the 3 datasets we are going to join them as one final dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9dd0f222",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final dataset shape: (1543, 2)\n",
      "Final dataset count:\n",
      "label    1543\n",
      "text     1543\n",
      "dtype: int64\n",
      "Final dataset labels: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Usuario\\AppData\\Local\\Temp\\ipykernel_14244\\563735502.py:2: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  train_df[\"label\"] = train_df[\"label\"].replace({'True': 1 , 'Fake': 0}).astype(\"int8\")\n",
      "C:\\Users\\Usuario\\AppData\\Local\\Temp\\ipykernel_14244\\563735502.py:3: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  development_df[\"label\"] = development_df[\"label\"].replace({'True': 1 , 'Fake': 0}).astype(\"int8\")\n"
     ]
    }
   ],
   "source": [
    "# Replace labels from \"Fake\" to 0 and \"True\" to 1\n",
    "train_df[\"label\"] = train_df[\"label\"].replace({'True': 1 , 'Fake': 0}).astype(\"int8\")\n",
    "development_df[\"label\"] = development_df[\"label\"].replace({'True': 1 , 'Fake': 0}).astype(\"int8\")\n",
    "# The test dataset has different labels (True/False)\n",
    "test_df[\"label\"] = test_df[\"label\"].replace({'True': 1 , 'False': 0}).astype(\"int8\")\n",
    "\n",
    "# Join all fake news corpush spanish datasets\n",
    "fake_news_corpus_spanish_final_df = pd.concat(objs=[train_df, development_df, test_df], ignore_index=True)\n",
    "fake_news_corpus_spanish_final_df = fake_news_corpus_spanish_final_df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "print(f\"Final dataset shape: {fake_news_corpus_spanish_final_df.shape}\")\n",
    "print(f\"Final dataset count:\\n{fake_news_corpus_spanish_final_df.count()}\")\n",
    "print(f\"Final dataset labels: {fake_news_corpus_spanish_final_df['label'].unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "efd863cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Articles length information: \n",
      "count    1543.000000\n",
      "mean      438.546338\n",
      "std       354.403013\n",
      "min        20.000000\n",
      "25%       231.000000\n",
      "50%       338.000000\n",
      "75%       528.000000\n",
      "max      4006.000000\n",
      "Name: length_words, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Create a column with the number of characters\n",
    "fake_news_corpus_spanish_final_df[\"length_words\"] = fake_news_corpus_spanish_final_df[\"text\"].str.split().str.len()\n",
    "\n",
    "print(\"Articles length information: \")\n",
    "print(fake_news_corpus_spanish_final_df[\"length_words\"].describe())\n",
    "\n",
    "fake_news_corpus_spanish_final_df = fake_news_corpus_spanish_final_df.drop(columns=[\"length_words\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d08034",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "After loading and reviewing all 4 datasets (including all files), I reached the conclusion that we have 2 datasets which containg long articles and 2 datasets that contain short articles:\n",
    "\n",
    "* `Fake News Corpus Spanish` + `Spanish Fake and Real News` - Containg long articles.\n",
    "* `Noticias falsas en español` + `Spanish Political Fake News` - Containg very short articles.\n",
    "\n",
    "We can't combine all datasets together as that would bring unbalance to our model. What we could do is use the short articles dataset (aprox. 50k articles) to **pre-fine-tune** the model and then use the 'good' dataset (with long articles and around 2k articles) to do the final **fine-tune** of the model (a.k.a. Sequential Fine Tuning ).\n",
    "\n",
    "The sequential fine tuning would go like this:\n",
    "\n",
    "1. The Foundation Model (`dccuchile/bert-base-spanish-wwm-uncased`)\n",
    "    * We start with a pre-trained BERT model that has already \"read\" a massive corpus of Spanish text (Wikipedia, legal documents, news).\n",
    "\n",
    "2. Intermediate Tuning (`50k Dataset`)\n",
    "    * In this stage, we take the generalist BERT model and train it on our large, noisy dataset to teach it the broad concept of Fake vs. Real news.\n",
    "    * The result is a model that understands Fake News in a general sense but is somewhat biased toward short, lower-quality text.\n",
    "\n",
    "3. Final Fine-Tuning (`2k Dataset`)\n",
    "    * We take the model from Stage 2 and fine-tune it on our high-quality “Gold Standard” dataset using a low learning rate to adapt it to long-form context and reliable ground-truth labels.\n",
    "    * This works because the model already knows Spanish from Stage 1 and already understands the general characteristics of Fake News from Stage 2.\n",
    "    * This final step simply aligns those learned patterns with the specific structure, nuance, and depth of our high-quality long articles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a6431d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Long Dataset\n",
    "final_long_df = pd.concat(objs=[spanish_fake_real_news_final_df, fake_news_corpus_spanish_final_df], ignore_index=True)\n",
    "final_long_df = final_long_df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# Final Short Dataset\n",
    "final_short_df = pd.concat(objs=[spanish_political_fake_news_df, true_fake_final_df], ignore_index=True)\n",
    "final_short_df = final_short_df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# Save csv files\n",
    "final_long_df.to_csv(\"../data/final_long_dataset.csv\", index=False)\n",
    "final_short_df.to_csv(\"../data/final_short_dataset.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
