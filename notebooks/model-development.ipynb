{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-70-NSrIhpqP"
      },
      "source": [
        "# Model Development\n",
        "\n",
        "In this notebook we are going to be preparing and training our model. As a base model (foundation) we are going to be using `\n",
        "bert-base-spanish-wwm-uncased`.\n",
        "\n",
        "Our objective is to build a classifier capable of predicting whether a news article is fake or real. To accomplish this, we will fine-tune the base model using the dataset prepared in`data-preparation.ipynb`.\n",
        "\n",
        "This are the steps we are going to be following:\n",
        "\n",
        "1. Load our data - Stored in a `.csv` file.\n",
        "2. Preprocess and Tokenize the data - Implement a truncation strategy to work with the 512 tokens.\n",
        "3. Create a `Dataset` object.\n",
        "5. Fine-Tune the pre-trained model.\n",
        "6. Evaluate the results - Check metrics on validation set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bXxcpisbjdmW"
      },
      "source": [
        "### Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ppXxKQ8ic_4A"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "import evaluate\n",
        "import numpy as np\n",
        "\n",
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer, TrainingArguments, Trainer\n",
        "from datasets import Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eGzYCWosj3MO"
      },
      "source": [
        "### Device agnostic code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ynP_jqvXdSIm",
        "outputId": "6bed9a6c-9d32-4d80-86e8-faec539534db"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running on: cuda\n"
          ]
        }
      ],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Running on: {device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZSPYNj_RkpEf"
      },
      "source": [
        "### Global variables\n",
        "\n",
        "The paths may be different depending if it is being run on **Google Colab** or locally."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yzHdRbAWkrUP"
      },
      "outputs": [],
      "source": [
        "LONG_DATASET_PATH = \"../data/final_long_dataset.csv\"\n",
        "SHORT_DATASET_PATH = \"../data/final_short_dataset.csv\"\n",
        "SAVE_STAGE1_MODEL_PATH = \"../models/fake-news-classifier-stage1\"\n",
        "SAVE_FINAL_MODEL_PATH = \"/content/models/fake-news-classifier-final-v2\"\n",
        "SAVE_TOKENIZER_PATH = \"../tokenizer\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iIC1HdqhkK4_"
      },
      "source": [
        "# Data Preprocessing & Tokenization\n",
        "\n",
        "In this stage we are going to be:\n",
        "\n",
        "* Loading our data from the `.csv` file.\n",
        "* Clean text (if needed).\n",
        "* Tokenize data - Handling truncation strategy.\n",
        "* Create `Dataset` object - With train/val/test splits."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IsoVqg16nvaz"
      },
      "source": [
        "#### Short Articles Dataset (`≃50k articles`)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pb-L6jlln7RI",
        "outputId": "6c356737-9828-4fc6-b7ae-9ee17864747f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Short articles dataframe was loaded from /content/final_short_dataset.csv successfully with a total of 59231 articles.\n"
          ]
        }
      ],
      "source": [
        "short_df_temp = pd.read_csv(SHORT_DATASET_PATH, names=[\"label\", \"title\", \"text\"], header=0)\n",
        "print(f\"Short articles dataframe was loaded from {SHORT_DATASET_PATH} successfully with a total of {short_df_temp.shape[0]} articles.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4JTwuUmVn7RI",
        "outputId": "cf03338f-e5c2-48f0-b1dd-03fcad2d0768"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Null values per column before cleanup:\n",
            "label       0\n",
            "title    2000\n",
            "text        0\n",
            "dtype: int64\n",
            "\n",
            "Null values per column after cleanup:\n",
            "label    0\n",
            "title    0\n",
            "text     0\n",
            "dtype: int64\n",
            "\n",
            "Final dataset length: 57231\n"
          ]
        }
      ],
      "source": [
        "# Check if dataset has any Null values\n",
        "print(f\"Null values per column before cleanup:\\n{short_df_temp.isnull().sum()}\\n\")\n",
        "short_df = short_df_temp.dropna().copy()\n",
        "print(f\"Null values per column after cleanup:\\n{short_df.isnull().sum()}\\n\")\n",
        "print(f\"Final dataset length: {short_df['text'].count()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5MNHMWnp2Z0C"
      },
      "source": [
        "### Add title to text with separator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "PjzM8LEW0qDR"
      },
      "outputs": [],
      "source": [
        "short_df[\"text\"] = short_df[\"title\"] + \". \" + short_df[\"text\"]\n",
        "short_df = short_df.drop(columns=[\"title\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JTqqSmxSnqH7"
      },
      "source": [
        "#### Long Articles Dataset (`≃2k articles`)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oM9Su22XkAAf",
        "outputId": "f272493e-58b2-443d-be87-e7ddb78cbd08"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Long articles dataframe was loaded from /content/final_long_dataset.csv successfully with a total of 2141 articles.\n"
          ]
        }
      ],
      "source": [
        "long_df = pd.read_csv(LONG_DATASET_PATH, names=[\"text\", \"label\"], header=0)\n",
        "print(f\"Long articles dataframe was loaded from {LONG_DATASET_PATH} successfully with a total of {long_df.shape[0]} articles.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sko1ULpZlXRI",
        "outputId": "6ba4310b-0d9d-4973-d039-2ef16cb1e263"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Null values per column:\n",
            "text     0\n",
            "label    0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Check if dataset has any Null values\n",
        "print(f\"Null values per column:\\n{long_df.isnull().sum()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aUJzGxDtmVgf"
      },
      "source": [
        "*Obervation: As we don't have any Null values we can proceed.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8HOum4_2mwXX"
      },
      "source": [
        "### Tokenization & Truncation\n",
        "\n",
        "We are going to use a strategy called `Head Truncation`, where we grab the first n tokens.\n",
        "\n",
        "In case this is not the best approach we can later try another strategy called `Head-Tail Truncation` where don't truncate only from one side but from the start and the end. This allows us to have n amount of tokens from the head and m amount of tokens from the tail. The problem with this is that it needs to be implemented manually and runs sequentially, making it NOT efficient at all.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319,
          "referenced_widgets": [
            "2e99a5a9d09f4e1ca3d86e1ac7c94506",
            "06340077206c458ba1d3191fa2698ffb",
            "40e935a3b46a40aa82b4b975f895a7a0",
            "b39eab8d26654ede96244ef04ab672ba",
            "4c6de43513cd4a8fb68af0f4fd2251e9",
            "e9811cb1c07041b6be9de5ee5f128a27",
            "70b5e4cae09d4a9da296ffe14917ae00",
            "c2a6698b57924032af74793ee314dd0b",
            "a24cda397e044945b82e346e411914e1",
            "6c2f1329da5948d49ad20ebd4bf53800",
            "1f2e403b2ba94ac394ccf898e28d6c59",
            "e2bf60d6260c43808c612de2fcc76270",
            "d3a25940bac64df08d354a24891920e7",
            "d55ed1c304a84d96be69457660da102d",
            "c5b2d1314c344ace9bf9612b096d9697",
            "67d4bf6100494156aee9007c68227de6",
            "817c88bb166743a8a42dbcf7a808fd5d",
            "917dabe1644c4e01b15fdaadc9686fd7",
            "57d0373984d14717aa89ddd32fcabcdc",
            "880403073d23490c9e98d32dde98fd6b",
            "61d272ee5bd9496fa43648a27d7b22c9",
            "ab24360ae041445eb8c8aab71b80b3c3",
            "78f74e33165047d8b6324a935e621417",
            "3f14ece5f4c244109a59980169909805",
            "70ee8466c3cb4f119680c08c9ebc1fef",
            "f6f1c19d37e54aeca0d86d2dde8cc964",
            "4169c8893dd644cead4b0642bb4b65a7",
            "fba1cb25d5a6420f961f15b6f8d73265",
            "c3115a587bb849a2a89cb9812fb4f945",
            "2772ea209df94654bad2c3238ef4c266",
            "7180067c12574cc59998234214050bde",
            "c6e1382b906947f0b847f084db504992",
            "44664e342b164b17a0767c728e37a3f3",
            "fde3f9be7cc04ef8a77489d88d9e01b4",
            "ef5649adc4d74f2ea13178fb0e14f9c0",
            "d4657781d02b43129df21a9424701d4f",
            "df7ba875061a41b2bf2863026fba3a2e",
            "33f37ef692784a26a5721f52740dea59",
            "1a08aad646eb48c6be7a8e7260a07d35",
            "d1697a352b9949ea81e9dc096c7caf92",
            "3858364c53934160a676f1d206f39bde",
            "18628c12773343fab497db7c08cf5012",
            "ec5b4443a1fe40f3bfa5a009311e1859",
            "4468838f600c4b2da36fcea28332b197",
            "c5b6c012f2f54e6792e52deb9eec1519",
            "ec26371e34604faa9f626f36a444e3fa",
            "ea821f22374d4a8cb301ac9dd82ac8ba",
            "19196e46595a4a0a9459ddeff2705140",
            "ca9c01c336d246e193d64d589034eb95",
            "1e848ce81f644cfb86322296b097f281",
            "57c4ba2563c24d5887be269167408d83",
            "572f116585314c3097780a317166bb90",
            "dc6e70cc69734914a14091313592f1d6",
            "f58f3335277446c4af725098e2d0b5d4",
            "6f98d3347d00462b8670c3a158858ca8"
          ]
        },
        "collapsed": true,
        "id": "6FSULNvrl7wW",
        "outputId": "3763d0cd-8943-47cf-bac1-45296a2e7fa5"
      },
      "outputs": [],
      "source": [
        "PRE_TRAINED_MODEL_NAME = \"dccuchile/bert-base-spanish-wwm-uncased\"\n",
        "\n",
        "print(f\"Loading Tokenizer for {PRE_TRAINED_MODEL_NAME}...\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"dccuchile/bert-base-spanish-wwm-uncased\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Save Tokenizer\n",
        "\n",
        "We save the tokenizer to have the whole model bundle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save tokenizer locally\n",
        "tokenizer.save_pretrained(SAVE_TOKENIZER_PATH)\n",
        "print(f\"Tokenizer saved locally to: {SAVE_TOKENIZER_PATH}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Oi64k2KvwjNP"
      },
      "outputs": [],
      "source": [
        "def preprocess_dataset(dataframe: pd.DataFrame,\n",
        "                       text_column: str = \"text\",\n",
        "                       label_column: str = \"label\") -> dict[str, any]:\n",
        "    \"\"\"\n",
        "    Preprocess dataframe with head truncation.\n",
        "\n",
        "    Args:\n",
        "        dataframe (pd.Dataframe): Pandas dataframe with our articles + labels\n",
        "        text_column (str): Name of column that contains articles text (default = \"text\")\n",
        "        label_colum (str): Name of column that contains articles labels (default = \"label\")\n",
        "\n",
        "    Returns:\n",
        "        Dictionary with inputs_ids, attention_masks and labels\n",
        "    \"\"\"\n",
        "    print(f\"Preprocessing {dataframe[text_column].count()} articles...\")\n",
        "    # Tokenize all articles at once\n",
        "    encoded = tokenizer(\n",
        "        dataframe[text_column].tolist(),\n",
        "        truncation=True,\n",
        "        max_length=512,\n",
        "        padding=\"max_length\",\n",
        "        return_tensors=None\n",
        "    )\n",
        "\n",
        "    return {\n",
        "        \"input_ids\": encoded[\"input_ids\"],\n",
        "        \"attention_mask\": encoded[\"attention_mask\"],\n",
        "        \"labels\": dataframe[label_column].tolist()\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sBpPgVPOx_Rv"
      },
      "source": [
        "### Create `Dataset` + Split into Train/Val/Test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NQaCUYuTpuWj"
      },
      "source": [
        "#### Short Articles Dataset (`≃50k articles`)\n",
        "\n",
        "For this dataset we are only going to split into training and eval as its going to be use to `pre-fine-tune` our transformer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i5yMRXqAp7Ib",
        "outputId": "cbf1675d-1818-4b47-93f9-e26d621bc0fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Preprocessing 57231 articles...\n",
            "Sucessfully split data into Train/Val:\n",
            "Train dataset: 45784 articles\n",
            "Validation dataset: 11447 articles\n"
          ]
        }
      ],
      "source": [
        "# Preprocess short articles\n",
        "processed_data_short = preprocess_dataset(dataframe=short_df)\n",
        "# Create hugging face Dataset\n",
        "dataset_short = Dataset.from_dict(processed_data_short)\n",
        "\n",
        "# Split data into Train/Validation\n",
        "train_test_split = dataset_short.train_test_split(test_size=0.2, shuffle=True)\n",
        "\n",
        "# Get train and test data\n",
        "train_data_short = train_test_split[\"train\"]\n",
        "val_data_short = train_test_split[\"test\"]\n",
        "\n",
        "print(f\"Sucessfully split data into Train/Val:\")\n",
        "print(f\"Train dataset: {train_data_short.num_rows} articles\")\n",
        "print(f\"Validation dataset: {val_data_short.num_rows} articles\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UKGbRJ7-p8UD"
      },
      "source": [
        "#### Long Articles Dataset (`≃2k articles`)\n",
        "\n",
        "Here we are going to do the full split between train/validation/test."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dqwTMJ7qxcru",
        "outputId": "cb4b64a9-9844-44c1-fa23-3d879dce5470"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Preprocessing 2141 articles...\n",
            "Sucessfully split data into Train/Val/Test:\n",
            "Train dataset: 1498 articles\n",
            "Validation dataset: 214 articles\n",
            "Test dataset: 429 articles\n"
          ]
        }
      ],
      "source": [
        "# Preprocess articles\n",
        "processed_data_long = preprocess_dataset(dataframe=long_df)\n",
        "# Create hugging face Dataset\n",
        "dataset_long = Dataset.from_dict(processed_data_long)\n",
        "\n",
        "# Split data into Train/Validation/Test\n",
        "train_test_split = dataset_long.train_test_split(test_size=0.2, shuffle=True)\n",
        "\n",
        "# Get train and test data\n",
        "train_data_long_temp = train_test_split[\"train\"]\n",
        "test_data_long = train_test_split[\"test\"]\n",
        "\n",
        "# Get validation data from train\n",
        "train_val_split = train_data_long_temp.train_test_split(test_size=0.125, shuffle=True)\n",
        "train_data_long = train_val_split[\"train\"]\n",
        "val_data_long = train_val_split[\"test\"]\n",
        "\n",
        "print(f\"Sucessfully split data into Train/Val/Test:\")\n",
        "print(f\"Train dataset: {train_data_long.num_rows} articles\")\n",
        "print(f\"Validation dataset: {val_data_long.num_rows} articles\")\n",
        "print(f\"Test dataset: {test_data_long.num_rows} articles\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CeEizIzn0BaP"
      },
      "source": [
        "# Fine-Tuning Model\n",
        "\n",
        "In this stage is where we use our pre-trained model `bert-base-spanish-wwm-uncased` and fine-tune it with our data.\n",
        "\n",
        "The first approach is going to be to train it only on our 2k long articles dataset, and see how it performs. After this or in case it doesn't perform as expected we will add an extra layer of fine-tuning between. In this layer we will use our 50k short articles dataset and see if it improves or not the performance of our custom transformer (`Sequential Fine-Tune`).\n",
        "\n",
        "In addition we are going to use our validation set to find \"good\" hyperparameters using `hyperparameter_search()`.\n",
        "\n",
        "The steps we are going to be following:\n",
        "\n",
        "* Create evaluation metrics.\n",
        "* Create model instance using `AutoModelForSequenceClassification`.\n",
        "* Create training arguments (`TrainingArguments`).\n",
        "* Create instance of `Trainer`.\n",
        "* Perform Hyperparameter search.\n",
        "* Train final model using best hyperparameters.\n",
        "\n",
        "\n",
        "*Note: After trying only with the 2k datasets and getting bad results, we are going for the other approch -> Sequential Fine-Tuninig.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zLYqMBI37wuL"
      },
      "source": [
        "### Create Evaluation Metrics\n",
        "\n",
        "We are going to be using the `accuracy`, `f1-score`, `precision` and `recall` metrics for evaluating our model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "149efe8d0a464f8ba755c658aa23065d",
            "7bc4481e6556414aa1718357bd5dea34",
            "51f8b82f406f4b079c07f6c5d4f86de7",
            "f45594eeb44443908b53b6b05d1c6368",
            "ce7a661889da4279b4b52f703eb85a89",
            "20df3e8e78b341f2b959b2bac90218bc",
            "35bdb38e40d34283a341bc61978fc6b6",
            "68dad669d7a24a59b9ac6e2b3f365924",
            "29fcf7a2e09e4c40b3ee8060eaa614b1",
            "fbed9fdf011244d6977c64527fb38c0e",
            "1096a5cb0944422a838adb4d151e507e",
            "ae70255b562a4eff9ed10347c166a691",
            "795afb9aee5b437dbe4a44abf6dd2e85",
            "a7b011db4a2f4a10b1b8ca8250a3b9ce",
            "342ffaecdcb948868bb9efa1266e17fc",
            "746a1faae1694510a234a817dac3f9e0",
            "11e4e04002ca4019a339499b0465c951",
            "e4d90986864c454eb4d1854af3171b38",
            "e1ddd724ca6345f290919f2751dfcd2b",
            "61c2b137fdb84e498e746413fa717281",
            "4b8219f70f094dd59ff555d5b073aff8",
            "de52df3672014756ba40aa3255f0df9d",
            "6884b7a03e984c24934d3e56e6fcfb93",
            "dc6c53f7da054ca9ad7e3f3c7e45c9cd",
            "930076eb8d15498784b1fab5672de413",
            "dbed577500b04137a893a484caeb23a6",
            "fe3029f663c643a387eebfd7ea36c3ae",
            "59df0321c92f4aa9ad420b02cf935826",
            "f7b1abc5eed44c39accc3b0655b3335e",
            "fe7be009bd444a7583c5ab92482ec363",
            "9c6a37eada4c4914a01db3163c9b6c26",
            "bfea80bc7a5b4c5480d37b8349f95cb6",
            "1c995cc272e0439aa5cc408023b9e771",
            "88f294e7d837489eaad0ae884c1fb424",
            "b673dc84ad2644bb9305826e5344832a",
            "a1f53f033ac042f58ef22f4bc7b0795a",
            "8e6dce140a394096ab27c3538c2e7620",
            "a78b5a5e82784236a5017dbcfdc70c1e",
            "1da91823826846bda1a59b5c8295d0ae",
            "163e5b2c32ed40d18ee4d687a4542893",
            "072687d013b2481ea9b2da398eee814c",
            "70cee99039264c65a9b94fc573bbac7a",
            "2161c0370f784a798c66721d07123d6d",
            "78d1492ea9874a2798f49ef34ce4bdf8"
          ]
        },
        "collapsed": true,
        "id": "2pmXH2QSx5cv",
        "outputId": "ec64411d-c691-4f7a-c318-68bcdfefc768"
      },
      "outputs": [],
      "source": [
        "metrics = evaluate.combine([\"accuracy\", \"precision\", \"recall\", \"f1\"])\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    \"\"\"\n",
        "    Computes metrics for our transformer model. It uses a combination of 'accuracy', 'precision', 'recall' and 'f1' metrics.\n",
        "\n",
        "    Args:\n",
        "        eval_pred (): Predictions\n",
        "\n",
        "    Returns:\n",
        "        Dictionary containing the metrics.\n",
        "    \"\"\"\n",
        "    # Destructure logits and labels\n",
        "    logits, labels = eval_pred\n",
        "    # Generate predictions\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "\n",
        "    return metrics.compute(predictions=predictions,\n",
        "                           references=labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mkZiDeAR-CmS"
      },
      "source": [
        "### Create Instance of `TrainingArguments`\n",
        "\n",
        "We are going to setup the main and fundamental arguments for our training:\n",
        "\n",
        "* `output_dir`: The output directory where the model predictions and checkpoints will be written.\n",
        "* `evaluation_strategy`: he evaluation strategy to adopt during training.\n",
        "* `save_strategy`: The checkpoint save strategy to adopt during training.\n",
        "* `load_best_model_at_end`: Whether or not to load the best model found during training at the end of training.\n",
        "* `metric_for_best_model`: Specify the metric to use to compare two different models.\n",
        "* `greater_is_better`: Specify if better models should have a greater metric or not.\n",
        "* `per_device_train_batch_size`: The batch size per device in training.\n",
        "* `per_device_eval_batch_size`: The batch size per device in evaluation.\n",
        "* `num_train_epochs`: Total number of training epochs to perform.\n",
        "* `learning_rate`: The initial learning rate for AdamW optimizer.\n",
        "* `weight_decay`: The weight decay to apply (if not zero) to all layers except all bias and LayerNorm weights in AdamW optimizer.\n",
        "* `logging_steps`: Number of update steps between two logs.\n",
        "* `warmup_ratio`: The warmup phase prevents large gradients early in training from destabilizing the model, leading to better performance and stability.\n",
        "* `save_total_limit`: Timit the total amount of checkpoints."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "u0pVXHMb8RNR"
      },
      "outputs": [],
      "source": [
        "# Stage 1 default training arguments\n",
        "training_args_stage1 = TrainingArguments(\n",
        "    output_dir=\"./results_stage1\",\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"f1\",\n",
        "    greater_is_better=True,\n",
        "    report_to=\"none\",\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=3,\n",
        "    learning_rate=2e-5,\n",
        "    weight_decay=0.01,\n",
        "    logging_steps=50,\n",
        "    warmup_ratio=0.1,\n",
        "    save_total_limit=2,\n",
        ")\n",
        "\n",
        "# Stage 2 default training arguments\n",
        "training_args_stage2 = TrainingArguments(\n",
        "    output_dir=\"./results_stage2\",\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"f1\",\n",
        "    greater_is_better=True,\n",
        "    report_to=\"none\",\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=5,\n",
        "    learning_rate=5e-6,\n",
        "    weight_decay=0.01,\n",
        "    logging_steps=10,\n",
        "    warmup_ratio=0.1,\n",
        "    save_total_limit=2,\n",
        "    gradient_accumulation_steps=2,\n",
        "    max_grad_norm=1.0,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fdJ3TjTYFTlY"
      },
      "source": [
        "### Load `bert-base-spanish-wwm-uncased` (base model)\n",
        "\n",
        "As mentioned before, we are going to first start only with the 2k long articles dataset. For this we are going to freezer part of the transformer and trian the classifier.\n",
        "\n",
        "In case the model doesn't perform well, we will include the 50k short articles dataset following this strategy:\n",
        "\n",
        "* Pre-Fine-Tune using the 50k dataset - Training everything for a couple of epochs.\n",
        "* Fine-Tune the model using the 2k dataset - Freeze only the encoder and train the classifier (what we are doing originally)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d_bOLvucr6D7"
      },
      "source": [
        "## Stage 1: Pre-Fine-Tune\n",
        "\n",
        "We are going to pre-fine-tune our base model using the 50k short articles dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "collapsed": true,
        "id": "cH85V7RkrzW_"
      },
      "outputs": [],
      "source": [
        "PRE_TRAINED_MODEL_NAME = \"dccuchile/bert-base-spanish-wwm-uncased\"\n",
        "\n",
        "def model_init_stage1():\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(\n",
        "        PRE_TRAINED_MODEL_NAME,\n",
        "        num_labels=2\n",
        "    )\n",
        "\n",
        "    # Freeze all parameters in the base BERT model first\n",
        "    for param in model.bert.parameters():\n",
        "        param.requires_grad = False\n",
        "\n",
        "    # Unfreeze last 2-3 layers of the encoder\n",
        "    for param in model.bert.encoder.layer[-2:].parameters():\n",
        "        param.requires_grad = True\n",
        "\n",
        "    # Unfreeze the pooler\n",
        "    for param in model.bert.pooler.parameters():\n",
        "        param.requires_grad = True\n",
        "\n",
        "    # Unfreeze the classifier head\n",
        "    for param in model.classifier.parameters():\n",
        "        param.requires_grad = True\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173,
          "referenced_widgets": [
            "4b409f20bd864552acec04a7b7500fcf",
            "4846118697b142a3b53d6f5c215424af",
            "b5828eddee44431884220cd986adbb51",
            "746aecf0db3242b99d33519c00607c85",
            "3fbb325fea664c8cab0668d03e59911b",
            "ea1d14276b8e4ae3a28068758a6885d2",
            "3085013514a04ea3ae42d8d68d893705",
            "7d2b5bcc5f6f4defbd1cb1ed2b307464",
            "fd12ef1212dc4d6d8712dbf9a9073a4f",
            "6f0f76d41b184b03a2a2449b466f1743",
            "514c10c708754147b42aad7c2ce926ed"
          ]
        },
        "collapsed": true,
        "id": "dY2PEyEmsJE2",
        "outputId": "9585c89c-2f1f-4d78-a614-8258e4b8ce4f"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4b409f20bd864552acec04a7b7500fcf",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dccuchile/bert-base-spanish-wwm-uncased and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model Parameters Count:\n",
            "Total: 109852418\n",
            "Trainable: 14767874\n",
            "Frozen: 95084544\n"
          ]
        }
      ],
      "source": [
        "# Temporal instance of the model to check parameters\n",
        "temp_model = model_init_stage1()\n",
        "\n",
        "total_params = sum(p.numel() for p in temp_model.parameters())\n",
        "trainable_params = sum(p.numel() for p in temp_model.parameters() if p.requires_grad)\n",
        "\n",
        "print(\"Model Parameters Count:\")\n",
        "print(f\"Total: {total_params}\")\n",
        "print(f\"Trainable: {trainable_params}\")\n",
        "print(f\"Frozen: {total_params - trainable_params}\")\n",
        "\n",
        "del temp_model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45jHh34BtcGd"
      },
      "source": [
        "### Create the `Trainer` instance for **Stage 1**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 259
        },
        "id": "6Apsfm4rtb7r",
        "outputId": "5e127cf9-847e-4469-8f2d-ba9efd6a54fc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dccuchile/bert-base-spanish-wwm-uncased and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dccuchile/bert-base-spanish-wwm-uncased and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='8586' max='8586' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [8586/8586 1:53:44, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.218800</td>\n",
              "      <td>0.193999</td>\n",
              "      <td>0.928802</td>\n",
              "      <td>0.931096</td>\n",
              "      <td>0.947487</td>\n",
              "      <td>0.939220</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.199600</td>\n",
              "      <td>0.176485</td>\n",
              "      <td>0.937364</td>\n",
              "      <td>0.949780</td>\n",
              "      <td>0.941920</td>\n",
              "      <td>0.945834</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.170900</td>\n",
              "      <td>0.168711</td>\n",
              "      <td>0.943479</td>\n",
              "      <td>0.944700</td>\n",
              "      <td>0.958772</td>\n",
              "      <td>0.951684</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Stage 1 trainer\n",
        "trainer_stage1 = Trainer(\n",
        "    model=None,\n",
        "    model_init=model_init_stage1,\n",
        "    args=training_args_stage1,\n",
        "    train_dataset=train_data_short,\n",
        "    eval_dataset=val_data_short,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "# Train stage 1 trainer\n",
        "trainer_stage1.train()\n",
        "# Save model to be use in stage 2\n",
        "trainer_stage1.save_model(SAVE_STAGE1_MODEL_PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9yn_f3hfs0R7"
      },
      "source": [
        "### Stage 2: Final Fine-Tune\n",
        "\n",
        "Using the pre-fine-tune model from stage 1, we are going to do a final fine-tune using the 2k long articles dataset, unfreezing the last 2 layers, the pooler and the classification head."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "GwaKK6pHBXhf"
      },
      "outputs": [],
      "source": [
        "PRE_TRAINED_MODEL_NAME = \"..models/fake-news-classifier-stage1\"\n",
        "\n",
        "def model_init_stage2():\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(\n",
        "        PRE_TRAINED_MODEL_NAME,\n",
        "    )\n",
        "\n",
        "    for param in model.bert.parameters():\n",
        "        param.requires_grad = False\n",
        "\n",
        "    # Unfreeze last 2 layers\n",
        "    for param in model.bert.encoder.layer[-1:].parameters():\n",
        "        param.requires_grad = True\n",
        "\n",
        "    # Unfreeze the pooler\n",
        "    for param in model.bert.pooler.parameters():\n",
        "        param.requires_grad = True\n",
        "\n",
        "    # Unfreeze the classifier head\n",
        "    for param in model.classifier.parameters():\n",
        "        param.requires_grad = True\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118,
          "referenced_widgets": [
            "fb6f640fa5884809969feedd76e9e568",
            "3facd0f253ea48abb34437451c832f20",
            "60b5fd2445f94ac79eadae86ca16016e",
            "5d1bfcfa31f84731bcfc5c4b4a10b561",
            "d727899cb21e43c99b8208002d4e6d4c",
            "744a7cd603cd49aa9a15ef35b39c40aa",
            "ac7d19ca85d34f0aa458b5b3b6c3c83e",
            "15a14ef4af2d45ea89446cfc917d7d36",
            "abbacbf5180c4da790588669a994ed93",
            "04f2666bb7f342059d0645dc182c7219",
            "3b461ee8213045d79f14a07409770b7b"
          ]
        },
        "id": "e_n_gPgPX51y",
        "outputId": "592adf91-7f47-43c6-9e7f-6d3600aa6728"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fb6f640fa5884809969feedd76e9e568",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model Parameters Count:\n",
            "Total: 109852418\n",
            "Trainable: 7680002\n",
            "Frozen: 102172416\n"
          ]
        }
      ],
      "source": [
        "# Temporal instance of the model to check parameters\n",
        "temp_model = model_init_stage2()\n",
        "\n",
        "total_params = sum(p.numel() for p in temp_model.parameters())\n",
        "trainable_params = sum(p.numel() for p in temp_model.parameters() if p.requires_grad)\n",
        "\n",
        "print(\"Model Parameters Count:\")\n",
        "print(f\"Total: {total_params}\")\n",
        "print(f\"Trainable: {trainable_params}\")\n",
        "print(f\"Frozen: {total_params - trainable_params}\")\n",
        "\n",
        "del temp_model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E3vpFCphtn2j"
      },
      "source": [
        "### Create the `Trainer` instance for **Stage 2**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "bINBOkG8bkjw",
        "outputId": "a3bf1654-640b-47cc-a511-6c5c1373af3c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-12-11 15:58:38,405] A new study created in memory with name: no-name-c4ecf54d-8543-4438-8092-58404c75f963\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='24' max='24' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [24/24 02:39, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.446400</td>\n",
              "      <td>1.393983</td>\n",
              "      <td>0.504673</td>\n",
              "      <td>0.519553</td>\n",
              "      <td>0.823009</td>\n",
              "      <td>0.636986</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.335400</td>\n",
              "      <td>1.344590</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.517045</td>\n",
              "      <td>0.805310</td>\n",
              "      <td>0.629758</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-12-11 16:01:26,105] Trial 0 finished with value: 2.452112974525857 and parameters: {'learning_rate': 2.8960728024867e-06, 'num_train_epochs': 2, 'seed': 19, 'per_device_train_batch_size': 64}. Best is trial 0 with value: 2.452112974525857.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='282' max='282' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [282/282 04:15, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.970700</td>\n",
              "      <td>0.996438</td>\n",
              "      <td>0.570093</td>\n",
              "      <td>0.574468</td>\n",
              "      <td>0.716814</td>\n",
              "      <td>0.637795</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.857800</td>\n",
              "      <td>0.861032</td>\n",
              "      <td>0.579439</td>\n",
              "      <td>0.589147</td>\n",
              "      <td>0.672566</td>\n",
              "      <td>0.628099</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.782600</td>\n",
              "      <td>0.829948</td>\n",
              "      <td>0.593458</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>0.690265</td>\n",
              "      <td>0.641975</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-12-11 16:05:44,907] Trial 1 finished with value: 2.5256987392928725 and parameters: {'learning_rate': 3.4604984292103825e-06, 'num_train_epochs': 3, 'seed': 26, 'per_device_train_batch_size': 8}. Best is trial 1 with value: 2.5256987392928725.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='188' max='188' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [188/188 01:30, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.846900</td>\n",
              "      <td>0.846468</td>\n",
              "      <td>0.593458</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>0.690265</td>\n",
              "      <td>0.641975</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-12-11 16:07:20,977] Trial 2 finished with value: 2.5256987392928725 and parameters: {'learning_rate': 6.426591924596102e-06, 'num_train_epochs': 1, 'seed': 8, 'per_device_train_batch_size': 4}. Best is trial 1 with value: 2.5256987392928725.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='188' max='188' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [188/188 01:30, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.847700</td>\n",
              "      <td>1.042910</td>\n",
              "      <td>0.537383</td>\n",
              "      <td>0.547297</td>\n",
              "      <td>0.716814</td>\n",
              "      <td>0.620690</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-12-11 16:08:55,891] Trial 3 finished with value: 2.42218428933184 and parameters: {'learning_rate': 2.864941345726809e-06, 'num_train_epochs': 1, 'seed': 2, 'per_device_train_batch_size': 4}. Best is trial 1 with value: 2.5256987392928725.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='376' max='376' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [376/376 03:01, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.461800</td>\n",
              "      <td>0.504006</td>\n",
              "      <td>0.738318</td>\n",
              "      <td>0.708029</td>\n",
              "      <td>0.858407</td>\n",
              "      <td>0.776000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.539200</td>\n",
              "      <td>0.465564</td>\n",
              "      <td>0.785047</td>\n",
              "      <td>0.781513</td>\n",
              "      <td>0.823009</td>\n",
              "      <td>0.801724</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-12-11 16:12:01,651] Trial 4 finished with value: 3.191292321502536 and parameters: {'learning_rate': 2.7924812330022644e-05, 'num_train_epochs': 2, 'seed': 5, 'per_device_train_batch_size': 4}. Best is trial 4 with value: 3.191292321502536.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='12' max='36' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [12/36 00:57 < 02:17, 0.17 it/s, Epoch 1/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.354400</td>\n",
              "      <td>1.217892</td>\n",
              "      <td>0.514019</td>\n",
              "      <td>0.527950</td>\n",
              "      <td>0.752212</td>\n",
              "      <td>0.620438</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-12-11 16:13:05,078] Trial 5 pruned. \n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='47' max='47' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [47/47 01:35, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.115300</td>\n",
              "      <td>1.193594</td>\n",
              "      <td>0.509346</td>\n",
              "      <td>0.524691</td>\n",
              "      <td>0.752212</td>\n",
              "      <td>0.618182</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-12-11 16:14:45,582] Trial 6 finished with value: 2.4044313599795637 and parameters: {'learning_rate': 4.014221245186902e-06, 'num_train_epochs': 1, 'seed': 37, 'per_device_train_batch_size': 16}. Best is trial 4 with value: 3.191292321502536.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='188' max='188' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [188/188 02:51, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.653800</td>\n",
              "      <td>0.655940</td>\n",
              "      <td>0.649533</td>\n",
              "      <td>0.663793</td>\n",
              "      <td>0.681416</td>\n",
              "      <td>0.672489</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.586900</td>\n",
              "      <td>0.595676</td>\n",
              "      <td>0.677570</td>\n",
              "      <td>0.669231</td>\n",
              "      <td>0.769912</td>\n",
              "      <td>0.716049</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-12-11 16:17:41,216] Trial 7 finished with value: 2.832761749829541 and parameters: {'learning_rate': 1.4834290833204622e-05, 'num_train_epochs': 2, 'seed': 21, 'per_device_train_batch_size': 8}. Best is trial 4 with value: 3.191292321502536.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='96' max='96' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [96/96 06:03, Epoch 4/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.698600</td>\n",
              "      <td>0.525170</td>\n",
              "      <td>0.766355</td>\n",
              "      <td>0.756098</td>\n",
              "      <td>0.823009</td>\n",
              "      <td>0.788136</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.440400</td>\n",
              "      <td>0.442135</td>\n",
              "      <td>0.794393</td>\n",
              "      <td>0.785124</td>\n",
              "      <td>0.840708</td>\n",
              "      <td>0.811966</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.328900</td>\n",
              "      <td>0.427918</td>\n",
              "      <td>0.803738</td>\n",
              "      <td>0.784000</td>\n",
              "      <td>0.867257</td>\n",
              "      <td>0.823529</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.289500</td>\n",
              "      <td>0.432030</td>\n",
              "      <td>0.808411</td>\n",
              "      <td>0.776923</td>\n",
              "      <td>0.893805</td>\n",
              "      <td>0.831276</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-12-11 16:23:50,079] Trial 8 finished with value: 3.31041532177547 and parameters: {'learning_rate': 9.897764875650956e-05, 'num_train_epochs': 4, 'seed': 9, 'per_device_train_batch_size': 32}. Best is trial 8 with value: 3.31041532177547.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='188' max='940' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [188/940 01:03 < 04:15, 2.94 it/s, Epoch 1/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.079400</td>\n",
              "      <td>0.928929</td>\n",
              "      <td>0.579439</td>\n",
              "      <td>0.590551</td>\n",
              "      <td>0.663717</td>\n",
              "      <td>0.625000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-12-11 16:24:55,843] Trial 9 pruned. \n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='96' max='96' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [96/96 06:02, Epoch 4/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.544833</td>\n",
              "      <td>0.733645</td>\n",
              "      <td>0.818182</td>\n",
              "      <td>0.637168</td>\n",
              "      <td>0.716418</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.455799</td>\n",
              "      <td>0.780374</td>\n",
              "      <td>0.761905</td>\n",
              "      <td>0.849558</td>\n",
              "      <td>0.803347</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.645900</td>\n",
              "      <td>0.437711</td>\n",
              "      <td>0.803738</td>\n",
              "      <td>0.770992</td>\n",
              "      <td>0.893805</td>\n",
              "      <td>0.827869</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.645900</td>\n",
              "      <td>0.425096</td>\n",
              "      <td>0.808411</td>\n",
              "      <td>0.776923</td>\n",
              "      <td>0.893805</td>\n",
              "      <td>0.831276</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Stage 2 trainer\n",
        "trainer_stage2 = Trainer(\n",
        "    model=None,\n",
        "    model_init=model_init_stage2,\n",
        "    args=training_args_stage2,\n",
        "    train_dataset=train_data_long,\n",
        "    eval_dataset=val_data_long,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "# Hyperparameter Search\n",
        "best_run = trainer_stage2.hyperparameter_search(n_trials=10,\n",
        "                                        direction=\"maximize\",\n",
        "                                        backend=\"optuna\")\n",
        "best_hyperparams = best_run.hyperparameters\n",
        "\n",
        "# Re-Create the TrainingArguments using the best hyperparameters\n",
        "training_args_best = TrainingArguments(\n",
        "    # Configuration\n",
        "    output_dir=\"./results\",\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"f1\",\n",
        "    greater_is_better=True,\n",
        "    report_to=\"none\",\n",
        "    # Use best hyperparameters from search\n",
        "    learning_rate=best_hyperparams[\"learning_rate\"],\n",
        "    per_device_train_batch_size=int(best_hyperparams.get(\"per_device_train_batch_size\", 16)),\n",
        "    per_device_eval_batch_size=int(best_hyperparams.get(\"per_device_eval_batch_size\", 16)),\n",
        "    num_train_epochs=int(best_hyperparams[\"num_train_epochs\"]),\n",
        "    weight_decay=best_hyperparams.get(\"weight_decay\", 0.01),\n",
        "    # General params\n",
        "    logging_steps=50,\n",
        "    warmup_ratio=0.1,\n",
        "    save_total_limit=2,\n",
        "    gradient_accumulation_steps=2,\n",
        ")\n",
        "\n",
        "# New Trainer Instance with the best hyperparameters\n",
        "final_trainer = Trainer(\n",
        "    model=None,\n",
        "    model_init=model_init_stage2,\n",
        "    args=training_args_best,\n",
        "    train_dataset=train_data_long,\n",
        "    eval_dataset=val_data_long,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "# Train final model using best hyperparameters\n",
        "final_trainer.train()\n",
        "# Save final model\n",
        "final_trainer.save_model(SAVE_FINAL_MODEL_PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "*Observation: The last table represents the model trained using the best hyperparameters (the hyperparameter search goes from 0 to 9 trials).*\n",
        "\n",
        "**Best Hyperparameters:**\n",
        "```\n",
        "{\n",
        " \"learning_rate\": 9.897764875650956e-05,\n",
        " \"num_train_epochs\": 4,\n",
        " \"seed\": 9,\n",
        " \"per_device_train_batch_size\": 32\n",
        "}\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ffcdbd14"
      },
      "source": [
        "### Evaluate Final Model on Test Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "ea9deb1f",
        "outputId": "3a92d0a1-f61f-47d9-99d4-7b413e7d5ed1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating final model on the test set...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='27' max='27' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [27/27 00:13]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Set Evaluation Results:\n",
            "  eval_loss: 0.4183\n",
            "  eval_accuracy: 0.8205\n",
            "  eval_precision: 0.7835\n",
            "  eval_recall: 0.8702\n",
            "  eval_f1: 0.8246\n",
            "  eval_runtime: 14.0762\n",
            "  eval_samples_per_second: 30.4770\n",
            "  eval_steps_per_second: 1.9180\n",
            "  epoch: 4.0000\n"
          ]
        }
      ],
      "source": [
        "print(\"Evaluating final model on the test set...\")\n",
        "results_final_model = final_trainer.evaluate(test_data_long)\n",
        "print(\"Test Set Evaluation Results:\")\n",
        "for key, value in results_final_model.items():\n",
        "    print(f\"  {key}: {value:.4f}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
